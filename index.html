<!-- ---
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: home
--- -->
<!doctype html>
<html lang='en'>

<head>
  <title>Nima Alamatsaz</title>

  <meta charset='utf-8'>
  <meta name='author' content='Nima Alamatsaz'>
  <meta name='copyright' content='Nima Alamatsaz'>
  <meta name='description' content='Personal website and portfolio of Nima Alamatsaz'>
  <meta name='viewport' content='width=device-width, initial-scale=1'>

  <link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css' integrity='sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2' crossorigin='anonymous'>
  <link rel='stylesheet' href='https://use.fontawesome.com/releases/v5.6.0/css/all.css' integrity='sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h' crossorigin='anonymous'>
  <link rel='stylesheet' href='https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css'>

  <script src='https://code.jquery.com/jquery-3.5.1.slim.min.js' integrity='sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj' crossorigin='anonymous'></script>
  <script src='https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js' integrity='sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx' crossorigin='anonymous'></script>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://googletagmanager.com/gtag/js?id=G-W4NCHJK0BE"></script>

  <script src='script.js'></script>
  <link rel='stylesheet' href='style.css'>
</head>


<body>
  <div class='page'>
    <div class='sidebar'>
      <div></div>

      <header>
        <img class='headshot' src='images/nima.jpg'>

        <h1>
          Nima Alamatsaz
        </h1>

        <h2>
          Data Scientist <br> Auditory Neuroscientist
        </h2>

        <div class='favicons'>
          <a href='mailto:'><i class='fas fa-envelope'></i></a>
          <a href='https://twitter.com/nialamat'><i class='fab fa-twitter'></i></a>
          <a href='https://github.com/nalamat'><i class='fab fa-github'></i></a>
          <a href='https://linkedin.com/in/nalamat'><i class='fab fa-linkedin'></i></a>
          <a href='https://scholar.google.com/citations?user=zjHQQEwAAAAJ&hl=en'><i class='ai ai-google-scholar big-icon'></i></a>
          <!-- <a href='https://linkedin.com/in/nalamat'><i class='fas fa-file-alt'></i></a> -->
        </div>

        <!-- <div class='construction'>
          Website under construction!
        </div> -->
      </header>

      <footer>
        © 2020 under <a href=https://gnu.org/licenses/gpl-3.0.en.html>GPLv3</a>
        | <a href='https://github.com/nalamat/nalamat.github.io'>View source</a>
        <br>
        Powered by <a href='https://pages.github.com'>GitHub Pages</a> and <a href='https://jekyllrb.com'>Jekyll</a>
      </footer>
    </div>


    <div class='content'>
      <main>
        <section>
          <p>I am a versatile self-starter with years of experience in programming with Python, C++, R; a strong background in machine learning, statistical modeling, signal processing; and engineering skills such as embedded systems and circuit design.</p>
          <p>My role as a graduate student in neuroscience has evolved around computational modeling of hearing phenomena through analyzing large amounts of brain signals by parallelized implementation of machine learning methods (such as K-SVD), and statistical modeling of human sound localization data using nonlinear mixed-effects model (NLME). Meanwhile, I enjoyed assisting Prof. Antje Ihlefeld in setting up an entire animal research lab (from designing hardware to writing software) and mentoring undergraduate students towards obtaining research grants.</p>
        </section>


        <h2>Education</h2>

        <section>
          <div class='item arrow'>
            <div class='cols'>
              <div><b>Ph.D. in Biomedical Engineering</b></div>
              <div class='info'>Sep 2015 - 2021 (Exp)</div>
            </div>
            <div class='cols'>
              <div><a class='nodecoration' href='https://njit.edu'>New Jersey Institute of Technology</a></div>
              <div class='info'>Newark, NJ</div>
            </div>

            <div class='more'>
              Received the <a class='emphasis' href='https://engineering.njit.edu/students-awards'>2020 NCE Outstanding Graduate Student Award</a>
              <br>
              Focus: Computational neuroscience, data science, signal processing of brain waves, statistical modeling
              <br>
              Dissertation: “Towards Understanding the Role of Central Processing in Release from Masking”
              <br>
              Advisor: Prof. Antje Ihlefeld
            </div>
          </div>

          <div class='item arrow'>
            <div class='cols'>
              <div><b><a class='nodecoration' href='https://micromasters.mit.edu/ds/'>MicroMasters in Statistics & Data Science</a></b></div>
              <div class='info'>Sep 2019 - 2021 (Exp)</div>
            </div>
            <div class='cols'>
              <div><a class='nodecoration' href='https://mit.edu'>Massachusetts Institute of Technology</a></div>
              <div class='info'>Online</div>
            </div>

            <div class='more'>
              Program offered by MIT on the edX platform
              <br>
              Focus: Probability, data analysis, statistics and machine learning
            </div>
          </div>

          <div class='item arrow'>
            <div class='cols'>
              <div><b>B.S. in Electrical Engineering</b></div>
              <div class='info'>Sep 2009 - Sep 2013</div>
            </div>
            <div class='cols'>
              <div><a class='nodecoration' href='https://ui.ac.ir/EN'>University of Isfahan</a></div>
              <div class='info'>Isfahan, Iran</div>
            </div>

            <div class='more'>
              <span class='emphasis'>Summa cum laude:</span> Ranked 1st among all Electrical Engineering undergraduate students
              <br>
              Microchip design, multi-objective optimization, genetic algorithm, parallelized simulation
              <br>
              Thesis: “Design of a Safe Low-Power Neural Micro-Stimulator with Gaussian Waveform”
            </div>
          </div>
        </section>


        <h2>Experience</h2>

        <section>
          <div class='item arrow'>
            <div class='cols'>
              <div><b>Graduate Research Assistant</b></div>
              <div class='info'>Sep 2015 - Current</div>
            </div>
            <div class='cols'>
              <div><a class='nodecoration' href='http://ihlefeldlab.com'>NESH Laboratory</a>, New Jersey Institute of Technology</div>
              <div class='info'>Newark, NJ</div>
            </div>
            <div class='more'>
              <p>
                By non-linear mixed-effects (NLME) modeling of human sound localization data we uncovered level dependence of perceived sound direction and proposed a unified computational model, overhauling the established view in the field. Further mining of the data has revealed even more interesting effects of short- and long-term adaptation when localizing with interaural time differences. Analysis in R with nlme package.
                <span class='float-right'>
                  <a class='button' href='https://doi.org/10.7554/eLife.47027'>Link</a>
                  <a class='button' href='https://doi.org/10.5061/dryad.t8c381f'>Code</a>
                </span>
              </p>
              <p>
                We discovered a reversal in coding scheme of target sounds in presence of background interference (the cocktail party problem) at negative signal-to-noise ratios using a combination of signal processing, pattern recognition, unsupervised and supervised learning methods to process electrical activity of neurons.
                <span class='float-right'>
                  <a class='button' href='https://github.com/nalamat/ephys'>Code</a>
                </span>
              </p>
              <p>
                Electrophysiology Auditory Recording System (EARS) project: I wrote an open source package in Python and GLSL (OpenGL Shading Language) for online processing, visualization and recording of brain signals, synchronized in microseconds with behavior of animals while implanted with microelectrodes.
                <span class='float-right'>
                  <a class='button' href='https://github.com/nalamat/ears'>Code</a>
                </span>
              </p>
              <p><span class='emphasis'>Mentored a team of six undergraduate students</span> towards obtaining research grants and completion of multiple projects ranging from neural signal processing and animal behavioral training to human psychoacoustics.</p>
              <p><span class='emphasis'>Assisted in setting up an entire animal research lab</span> from the ground up under supervision of Prof. Antje Ihlefeld.</p>
            </div>
          </div>

          <div class='item arrow'>
            <div class='cols'>
              <div><b>Graduate Research Assistant</b></div>
              <div class='info'>Jan 2016 - Jun 2016</div>
            </div>
            <div class='cols'>
              <div><a class='nodecoration' href='https://sites.rutgers.edu/pare-lab/'>Laboratory of Denis Paré</a>, Rutgers University</div>
              <div class='info'>Newark, NJ</div>
            </div>
            <div class='more'>
              <p>Custom implementation of the K-SVD unsupervised dictionary learning (inspired by image processing literature) in combination with matching pursuit and Gabor atom decomposition for analysis of brain waves and unsupervised recognition of sparse events. Initially written in Matlab, reimplemented in C++ with CUDA GPU acceleration.</p>
            </div>
          </div>

          <div class='item arrow'>
            <div class='cols'>
              <div><b>Research & Development Engineer</b></div>
              <div class='info'>May 2013 - May 2014</div>
            </div>
            <div class='cols'>
              <div><a class='nodecoration' href='https://novinmed.com/?lang=en'>Novin Medical Engineering Co.</a></div>
              <div class='info'>Isfahan, Iran</div>
            </div>
            <div class='more'>
              <p>Embedded systems and software development.</p>
              <p>Design of a modern ARM-based platform running on Windows Embedded along with a software framework and touch graphical user interface written in C# for the next generation devices of Novin Company.</p>
              <p>Low level drivers written in C++ facilitating real-time interaction of the software framework with different hardware peripherals for stimulator, interferential, laser and magnet therapy devices.</p>
              <p>High speed transfer of real-time data from an ARM microcontroller to another microcontroller or PC via the bulk transfer protocol of universal serial bus (USB) written in C++.</p>
            </div>
          </div>

          <div class='item arrow'>
            <div class='cols'>
              <div><b>Cofounder & Lead Engineer</b></div>
              <div class='info'>Jul 2012 - March 2014</div>
            </div>
            <div class='cols'>
              <div>Mahoor Engineering Co. (Startup)</div>
              <div class='info'>Isfahan Sci. & Tech. Town, Iran</div>
            </div>
            <div class='more'>
              <p>Electronic circuit design and software development.</p>
              <p>Proposed and partially implemented a robotic system with two arms for automation of steel processing laboratory of Mobarakeh Steel Company (Isfahan, Iran). Data from a PrimeSense depth camera installed on the first robotic arm combined with inverse kinematics was utilized to scan and construct a 3D cloud point of steel samples and the lab environment. This information was further used to automate steel sample preparation via rule-based artificial intelligence implemented on the second arm.</p>
            </div>
          </div>
        </section>


        <h2>Projects</h2>

        <section>
          <div class='card-container'>
            <div class='card'>
              <a href='https://github.com/nalamat/ears'>
                <div class='card-content'>
                  <h3><img src='images/ears.svg' style='position: relative; top: -.1em; width: 1.1em;'> EARS</h3>
                  <img src='images/ears.png'>
                  <p>Electrophysiology Auditory Recording System</p>
                </div>
                <div class='card-tags'>
                  <div class='tag python'></div>
                  <div class='tag glsl'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/ephys'>
                <div class='card-content'>
                  <h3>ePhys</h3>
                  <img src='images/ephys.png' style='padding: 0 5%;'>
                  <p>Analysis of neural recordings from auditory cortex</p>
                </div>
                <div class='card-tags'>
                  <div class='tag matlab'></div>
                  <div class='tag r'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/pypeline'>
                <div class='card-content'>
                  <h3>Pypeline</h3>
                  <img src='images/pypeline.png' style='padding: 9% 6%; padding-bottom: 3%;'>
                  <p>Object-oriented model for online processing of data streams</p>
                </div>
                <div class='card-tags'>
                  <div class='tag python'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/glplotlib'>
                <div class='card-content'>
                  <h3>glPlotLib</h3>
                  <img src='images/glplotlib.png'>
                  <p>Real-time GPU-accelerated plotting toolbox</p>
                </div>
                <div class='card-tags'>
                  <div class='tag python'></div>
                  <div class='tag glsl'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/mriviewer'>
                <div class='card-content'>
                  <h3>MRI Viewer</h3>
                  <img src='images/mriviewer.png'>
                  <p>Interactive UI for 3D analysis of MRI images</p>
                </div>
                <div class='card-tags'>
                  <div class='tag matlab'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://datadryad.org/stash/dataset/doi:10.5061/dryad.t8c381f'>
                <div class='card-content'>
                  <h3>nlme.pwr</h3>
                  <img src='images/nlme.pwr.png' style='padding: .1rem .1rem;'>
                  <p>Power analysis for Nonlinear Mixed-Effects (NLME) models</p>
                </div>
                <div class='card-tags'>
                  <div class='tag r'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/circuitoptim'>
                <div class='card-content'>
                  <h3>Circuit Optim</h3>
                  <img src='images/circuitoptim.png' style='padding: 2% 9%; padding-bottom: 0;'>
                  <p>A circuit optimization toolbox for MATLAB</p>
                </div>
                <div class='card-tags'>
                  <div class='tag matlab'></div>
                  <div class='tag cad'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/bcomp'>
                <div class='card-content'>
                  <h3>BCOMP</h3>
                  <img src='images/bcomp.png' style='padding: 5% 6%; padding-bottom: 0%;'>
                  <p>Gate-level simulation of the Basic computer</p>
                </div>
                <div class='card-tags'>
                  <div class='tag cad'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/basm'>
                <div class='card-content'>
                  <h3>BASM</h3>
                  <img src='images/basm.png'>
                  <p>The Basic computer assembler</p>
                </div>
                <div class='card-tags'>
                  <div class='tag cpp'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/easydaqmx'>
                <div class='card-content'>
                  <h3>EasyDAQmx</h3>
                  <img src='images/easydaqmx.jpg'>
                  <p>No-brainer object-oriented interface for NI DAQ devices</p>
                </div>
                <div class='card-tags'>
                  <div class='tag python'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='javascript:;'>
                <div class='card-content'>
                  <h3>Audio Calibration</h3>
                  <img src='images/audio-calibration.jpg'>
                  <p>Toolbox for calibrating frequency response of audio playback systems</p>
                </div>
                <div class='card-tags'>
                  <div class='tag python'></div>
                  <div class='tag matlab'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/avroscope'>
                <div class='card-content'>
                  <h3>AVROscope</h3>
                  <p>A low-cost low-frequency USB oscilloscope using Atmel AVR microcontroller</p>
                </div>
                <div class='card-tags'>
                  <div class='tag cpp'></div>
                  <div class='tag cs'></div>
                  <div class='tag cad'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/ajaxify-wp'>
                <div class='card-content'>
                  <h3>Ajaxify WP</h3>
                  <p>Hybrid ajaxify plugin for WordPress, load pages with Ajax while keeping normal link behavior intact</p>
                </div>
                <div class='card-tags'>
                  <div class='tag css'></div>
                  <div class='tag js'></div>
                </div>
              </a>
            </div>

            <div class='card'>
              <a href='https://github.com/nalamat/smscontroller'>
                <div class='card-content'>
                  <h3>SMS Controller</h3>
                  <p>Remotely control home appliances with text message commands</p>
                </div>
                <div class='card-tags'>
                  <div class='tag cpp'></div>
                  <div class='tag cad'></div>
                </div>
              </a>
            </div>
          </div>
        </section>


        <h2>Publications</h2>

        <section>
          <div class='item arrow'>
            <h3>Hemodynamic responses link individual differences in informational masking to the vicinity of superior temporal gyrus</h3>
            <div class='cols'>
              <div>
                M Zhang, <b>N Alamatsaz</b>, A Ihlefeld
                <br>
                <i>bioRxiv</i>, 2020
              </div>
              <div class='buttons'>
                <a class='button' href='https://biorxiv.org/content/10.1101/2020.08.21.261222v1.abstract'>Link</a>
                <a class='button' href='https://biorxiv.org/content/biorxiv/early/2020/08/23/2020.08.21.261222.full.pdf'>PDF</a>
                <!-- <a class='button' href='https://doi.org/10.1101/2020.08.21.261222'>DOI</a> -->
              </div>
            </div>
            <div class='more'><p>
              Suppressing unwanted background sound is crucial for aural communication. Public spaces often contain a particularly disruptive background sound, called informational masking (IM). At present, IM is identified operationally: when a target should be audible, based on suprathreshold target/masker energy ratios, yet cannot be heard because perceptually similar background sound interferes. Here, behavioral experiments combined with functional near infrared spectroscopy identify brain regions that predict individual vulnerability to IM. Results show that tasked-evoked blood oxygenation changes near the superior temporal gyrus (STG) and behavioral speech detection performance covary for same-ear IM background sound, suggesting that the STG is part of an IM-dependent network. Moreover, listeners who are more vulnerable to IM show an increased metabolic need for oxygen near STG. In contrast, task-evoked responses in a region of lateral frontal cortex, the caudal inferior frontal sulcus (cIFS), do not predict behavioral sensitivity, suggesting that the cIFS belongs to an IM-independent network.
            </p></div>
          </div>

          <div class='item arrow'>
            <h3>Teaching Electronic Circuit Fundamentals via Remote Laboratory Curriculum</h3>
            <div class='cols'>
              <div>
                <b>N Alamatsaz</b>, A Ihlefeld
                <br>
                <i>Biomedical Engineering Education</i>, pp. 1-4, 2020
              </div>
              <div class='buttons'>
                <a class='button' href='https://link.springer.com/article/10.1007/s43683-020-00008-x'>Link</a>
                <a class='button' href='https://link.springer.com/content/pdf/10.1007/s43683-020-00008-x.pdf'>PDF</a>
                <!-- <a class='button' href='https://doi.org/10.1007/s43683-020-00008-x'>DOI</a> -->
                <a class='button' href='https://zenodo.org/record/3952828#.X9T5Ai1h1QI'>Code</a>
              </div>
            </div>
            <div class='more'><p>
              The course “Electrical Fundamentals” (EF) is a core requirement for all undergraduate students in our biomedical engineering program. The curriculum introduces general principles of device development for electronics-based bioinstrumentation, comprehensively covering foundational acquisition concepts for bioelectric signals. Laboratory-based learning modules provide hands-on experience with circuit fundamentals. We here introduce our six-hour lab curriculum for distance learning, which we developed in response to the COVID-19 outbreak.
            </p></div>
          </div>

          <div class='item arrow'>
            <h3>Population rate-coding predicts correctly that human sound localization depends on sound intensity</h3>
            <div class='cols'>
              <div>
                A Ihlefeld, <b>N Alamatsaz</b>, RM Shapley
                <br>
                <i>eLife</i>, <i>8</i>, p.e47027, 2019
              </div>
              <div class='buttons'>
                <a class='button' href='https://elifesciences.org/articles/47027'>Link</a>
                <a class='button' href='https://elifesciences.org/download/aHR0cHM6Ly9jZG4uZWxpZmVzY2llbmNlcy5vcmcvYXJ0aWNsZXMvNDcwMjcvZWxpZmUtNDcwMjctdjEucGRmP2Nhbm9uaWNhbFVyaT1odHRwczovL2VsaWZlc2NpZW5jZXMub3JnL2FydGljbGVzLzQ3MDI3/elife-47027-v1.pdf?_hash=hRt9YYEDjMC6en%2ByELcWidEAE%2FV0sCMINFxYk4N%2Biqo%3D'>PDF</a>
                <!-- <a class='button' href='https://doi.org/10.7554/eLife.47027'>DOI</a> -->
                <a class='button' href='https://doi.org/10.5061/dryad.t8c381f'>Code</a>
              </div>
            </div>
            <div class='more'><p>
              Human sound localization is an important computation performed by the brain. Models of sound localization commonly assume that sound lateralization from interaural time differences is level invariant. Here we observe that two prevalent theories of sound localization make opposing predictions. The labelled-line model encodes location through tuned representations of spatial location and predicts that perceived direction is level invariant. In contrast, the hemispheric-difference model encodes location through spike-rate and predicts that perceived direction becomes medially biased at low sound levels. Here, behavioral experiments find that softer sounds are perceived closer to midline than louder sounds, favoring rate-coding models of human sound localization. Analogously, visual depth perception, which is based on interocular disparity, depends on the contrast of the target. The similar results in hearing and vision suggest that the brain may use a canonical computation of location: encoding perceived location through population spike rate relative to baseline.
            </p></div>
          </div>

          <div class='item arrow'>
            <h3>Leveraging adaptation to study perceptual weighting of interaural time differences</h3>
            <div class='cols'>
              <div>
                <b>N Alamatsaz</b>, A Ihlefeld
                <br>
                <i>International Congress on Acoustics (ICA)</i>, vol. 23, no. 1, pp. 8253-8256, 2019
              </div>
              <div class='buttons'>
                <a class='button' href='https://www.researchgate.net/profile/Nima_Alamatsaz/publication/338557619_Leveraging_adaptation_to_study_perceptual_weighting_of_interaural_time_differences/links/5e1ca52e92851c8364cbb7c8/Leveraging-adaptation-to-study-perceptual-weighting-of-interaural-time-differences.pdf'>PDF</a>
              </div>
            </div>
            <div class='more'><p>
              An important question in auditory cognition is how we perceive the location of an object in space. Converging evidence from animal models and humans suggests that when judging sound direction, the central nervous system weighs the anticipated reliability of binaural cues. Here, we used short-term adaptation to bias normal-hearing listeners towards source direction favoring either the left or the right frontal quadrant. Listeners rated perceived laterality of tokens of band-pass filtered noise (300 Hz-1200 Hz) with interaural time differences that were randomly selected from a uniform distribution spanning either -375 to 0 µs or 0 to 375 µs. Using non-linear mixed effects modeling of behavioral laterality reports, we tested how exposure to source quadrant affects how listeners weigh the reliability of interaural time differences. The cue reliability hypothesis predicts that perceived direction should be skewed, such that unreliable frontal source angles are more affected by short-term adaptation than the more reliable lateral source angles. Alternatively, short-term adaptation may affect all source angles equally, predicting an overall shift in perceived direction. Results show that frontal angles are more strongly affected by short-term adaptation than lateral angles, supporting the cue reliability hypothesis.
            </p></div>
          </div>

          <div class='item arrow'>
            <h3>Circling back on theories of sound localization</h3>
            <div class='cols'>
              <div>
                A Ihlefeld, <b>N Alamatsaz</b>, RM Shapley
                <br>
                <i>The Journal of the Acoustical Society of America (ASA)</i>, vol. 145, no. 3, pp. 1759, 2019
              </div>
              <div class='buttons'>
                <a class='button' href='https://asa.scitation.org/doi/abs/10.1121/1.5101438'>Link</a>
                <!-- <a class='button' href='https://doi.org/10.1121/1.5101438'>DOI</a> -->
              </div>
            </div>
            <div class='more'>
              <p>
                An important question of human perception is how we localize target objects in space. Through our eyes and skin, activation patterns on the sensory epithelium suffice to cue us about a target’s location. However, for our ears, the brain has to compute where a sound source is located. One important cue for computing sound direction is the time difference in arrival of acoustic energy reaching each ear, the interaural time difference (ITD). With behavioral experiments on sound lateralization as a function of sound intensity, we tested how the computation of sound location with ITDs is done. We tested twelve naïve normal-hearing listeners (ages 18–27, five females). Stimuli consisted of low-frequency noise tokens that were bandlimited from 300 to 122 Hz, from 5 to 25 dB sensation level. Without response feedback, listeners were initially trained to reliably judge the direction of a sound source and then tested on where they heard the sound. We found that softer sounds tend to be localized closer to midline as compared to louder sound. This finding raises doubt on one major theory of sound localization, the labeled-line theory, and supports another main contender, population rate based coding.
              </p>
            </div>
          </div>

          <div class='item arrow'>
            <h3>The role of central processing in modulation masking release</h3>
            <div class='cols'>
              <div>
                <b>N Alamatsaz</b>, A Ihlefeld
                <br>
                <i>The Journal of the Acoustical Society of America (ASA)</i>, vol. 144, no. 3, pp. 1900, 2018
              </div>
              <div class='buttons'>
                <a class='button' href='https://asa.scitation.org/doi/abs/10.1121/1.5068321'>Link</a>
                <!-- <a class='button' href='https://doi.org/10.1121/1.5068321'>DOI</a> -->
              </div>
            </div>
            <div class='more'>
              <p>
                When background sound is present, hearing impaired (HI) individuals and cochlear-implant (CI) listeners typically are worse at hearing out target sound as compared to normal-hearing (NH) listeners. This perceptual deficit occurs both when the background consists of noise that fluctuates over time (“modulated”) and for stationary background noise (“unmodulated”). In addition, the difference in thresholds between tone detection in modulated and unmodulated noise, referred to as modulation masking release (MMR), is much reduced or absent in HI and CI as compared to NH. Both peripheral and central processing mechanisms contribute to MMR. We previously showed that central MMR is reduced in human CI listeners, and that sound deprivation reduces central MMR in Mongolian gerbils. Here, we began to explore the neurobiological basis of central MMR. NH gerbils were trained to hear out target tones (1 kHz) in modulated (10-Hz rectangularly gated) versus unmodulated bandlimited background noise, and chronically implanted with recording electrodes in core auditory cortex. Neural discharge was analyzed as a function of the broadband energy ratio between target and background sound to determine how different types of background sound affect neural information transmission in awake behaving gerbil. Preliminary results will be discussed in the context of how hearing loss may affect central MMR.
              </p>
            </div>
          </div>

          <div class='item arrow'>
            <h3>Traffic volume reduction in smart grid networks by a cooperative intelligent interpolation technique</h3>
            <div class='cols'>
              <div>
                A Boustani, N Alamatsaz, <b>N Alamatsaz</b>, A Boustani
                <br>
                <i>Consumer Communications & Networking Conference (CCNC)</i>, <i>15th IEEE Annual</i>, pp. 1-7, 2018
              </div>
              <div class='buttons'>
                <a class='button' href='https://ieeexplore.ieee.org/abstract/document/8319265/'>Link</a>
                <a class='button' href='https://researchgate.net/profile/Nima_Alamatsaz/publication/323863327_Traffic_volume_reduction_in_smart_grid_networks_by_a_cooperative_intelligent_interpolation_technique/links/5e1ca3774585159aa4ce6baf/Traffic-volume-reduction-in-smart-grid-networks-by-a-cooperative-intelligent-interpolation-technique.pdf'>PDF</a>
                <!-- <a class='button' href='https://doi.org/10.1109/CCNC.2018.8319265'>DOI</a> -->
              </div>
            </div>
            <div class='more'>
              <p>
                Leveraging a modern communication network, the power industry is moving towards the next generation power grid, the smart grid. This new communication-based power grid is expected to change the way electricity is generated, distributed, and transmitted to the consumers by enhancing the reliability, efficiency, sustainability, and economics of the grid. However, due to the high volume, high granularity, and frequency of the data generated by smart electricity meters, careful planning and management of this communication network is essential. Given the potential large-scale future deployment of the smart grid, power companies face possible network capacity limitations. Therefore, efficient utilization of the Smart Grid Network (SGN) should be studied. In this paper, we introduce a smart interpolation scheme for reducing the volume of information transmitted in a smart grid backhaul network without any precision reduction or loss of benefit. Utilizing concepts of Spread Spectrum Communications, smart nodes at utility control centers are able to intelligently infer omitted data and interpolate the original message. By means of extensive evaluations, we show that our scheme significantly improves network utilization and decreases volume of the traffic in a smart grid network.
              </p>
            </div>
          </div>

          <div class='item arrow'>
            <h3>Towards Efficient Privacy-Preserving Data Aggregation for Advanced Metering Infrastructure</h3>
            <div class='cols'>
              <div>
                N Alamatsaz, A Boustani, <b>N Alamatsaz</b>, A Boustani
                <br>
                <i>The International Journal of Computer Networks & Communications (IJCNC)</i>, vol. 9, no. 5, 2017
              </div>
              <div class='buttons'>
                <a class='button' href='https://ijcnc.com/ijcnc-8-2/'>Link</a>
                <a class='button' href='https://aircconline.com/ijcnc/V9N5/9517cnc08.pdf'>PDF</a>
                <!-- <a class='button' href='https://doi.org/10.5121/ijcnc.2017.9508'>DOI</a> -->
              </div>
            </div>
            <div class='more'>
              <p>
                Recent changes to the existing power grid are expected to influence the way energy is pro-vided and consumed by customers. Advanced Metering Infrastructure (AMI) is a tool to incorporate these changes for modernizing the electricity grid. Growing energy needs are forcing government agencies and utility companies to move towards AMI systems as part of larger smart grid initiatives. The smart grid promises to enable a more reliable, sustainable, and efficient power grid by taking advantage of information and communication technologies. However, this information-based power grid can reveal sensitive private information from the user’s perspective due to its ability to gather highly-granular power consumption data. This has resulted in limited consumer acceptance and proliferation of the smart grid. Hence, it is crucial to design a mechanism to prevent the leakage of such sensitive consumer usage information in smart grid. Among different solutions for preserving consumer privacy in Smart Grid Networks (SGN), private data aggregation techniques have received a tremendous focus from security researchers. Existing privacy-preserving aggregation mechanisms in SGNs utilize cryptographic techniques, specifically homomorphic properties of public-key cryp- tosystems. Such homomorphic approaches are bandwidth-intensive (due to large output blocks they generate), and in most cases, are computationally complex. In this paper, we present a novel and efficient CDMA-based approach to achieve privacy-preserving aggregation in SGNs by utilizing ran- dom perturbation of power consumption data and with limited use of traditional cryptography. We evaluate and validate the efficiency and performance of our proposed privacy-preserving data ag-gregation scheme through extensive statistical analyses and simulations.
              </p>
            </div>
          </div>

          <div class='item arrow'>
            <h3>Neural correlates of modulation masking release: The role of sound deprivation</h3>
            <div class='cols'>
              <div>
                A Ihlefeld, M Ning, SS Chaubal, <b>N Alamatsaz</b>
                <br>
                <i>The Journal of the Acoustical Society of America (ASA)</i>, vol. 141, no. 5, pp. 3894, 2017
              </div>
              <div class='buttons'>
                <a class='button' href='https://asa.scitation.org/doi/abs/10.1121/1.4988741'>Link</a>
                <!-- <a class='button' href='https://doi.org/10.1121/1.4988741'>DOI</a> -->
              </div>
            </div>
            <div class='more'>
              <p>
                It is well documented that for tone detection in background noise, normally-hearing (NH) listeners have better behavioral thresholds when that noise is temporally modulated as compared to temporally unmodulated, a perceptual phenomenon referred to as Modulation Masking Release (MMR). However, hearing impaired listeners often do not show a dramatic difference in performance across these two tasks. Behavioral evidence from Mongolian gerbils (Meriones unguiculatus) with conductive hearing loss (CHL) supports the idea that sound deprivation alone can reduce MMR. Here, MMR was assessed in core auditory cortex in three NH animals, and one animal with CHL. Trained, awake gerbils listened passively to a target tone (1 kHz) embedded in modulated or unmodulated noise while a 16-channel chronically implanted microelectrode array recorded multi-unit neural spike activity in core auditory cortex. Results reveal that rate code correlates with behavioral thresholds at positive, but not negative Signal-to-Noise ratios. Effect of sound deprivation on MMR will be discussed using a Wilson-Cowan neural network model of cortical function.
              </p>
            </div>
          </div>

          <div class='item arrow'>
            <h3>The effect of sound intensity on lateralization with interaural time differences</h3>
            <div class='cols'>
              <div>
                <b>N Alamatsaz</b>, RM Shapley, A Ihlefeld
                <br>
                <i>The Journal of the Acoustical Society of America (ASA)</i>, vol. 141, no. 5, pp. 3639, 2017
              </div>
              <div class='buttons'>
                <a class='button' href='https://asa.scitation.org/doi/abs/10.1121/1.4987851'>Link</a>
                <!-- <a class='button' href='https://doi.org/10.1121/1.4987851'>DOI</a> -->
              </div>
            </div>
            <div class='more'>
              <p>
                Previous studies examining the effect of sound intensity on ITD lateralization disagree on whether ITD lateralization changes with increasing sound level. We tested how sound intensity affects lateralization in three experiments. In all experiments, normal-hearing listeners judged the lateralization of band-limited target noise tokens (300 to 1200 Hz, 1 s duration, 10-ms cos-squared ramp, presented with insert earphones). For each ear and target noise, sensation level (SL) was estimated using two-down one-up adaptive tracking. Each target stimulus contained an ITD of 0, 75, 150, 225, 300, or 375 µs and was presented at 10, 25, or 40 dB SL. In experiment 1, listeners matched the ITD of a variable-ITD pointer (25 dB SL, 300-1200 Hz, 1 s duration, 10-ms cos-squared ramp) to each of the target tokens. In experiment 2, in each two-interval trial of a 2-AFC paradigm, the standard stimulus consisted of the same noise token as in experiment 1 and the signal stimulus had a randomly chosen ITD of +/− 0, 25, 50 or 75 µs relative to the target ITD. Listeners reported whether the sound moved to the left or to the right, and thresholds were estimated at the “50%-right” point. In experiment 3, listeners indicated the perceived laterality by visually pointing on a graphical user interface. Preliminary data suggest that sound level affects lateralization, but that individual differences require testing of a greater number listeners than have historically been assessed.
              </p>
            </div>
          </div>

          <div class='item'>
            <h3>Towards Improved Safety, Selectivity and Energy Efficiency of Retinal Stimulation</h3>
            <div class='cols'>
              <div>
                <b>N Alamatsaz</b>, S Moradi, P Moallem
                <br>
                <i>Iranian Conference on Biomedical Engineering (ICBME)</i>, vol. 21, 2014
              </div>
              <div class='buttons'>
                <a class='button' href='https://www.researchgate.net/profile/Saed_Moradi/publication/269105904_Towards_Improved_Safety_Selectivity_and_Energy_Efficiency_of_Retinal_Stimulation/links/561662a508ae73279641e948/Towards-Improved-Safety-Selectivity-and-Energy-Efficiency-of-Retinal-Stimulation.pdf?_sg%5B0%5D=_ZtQDRFX2AyiBFc85FvDIldJBqDiJWEVFFwTapWbsTxgHTanNRyTy1LpVKvXV_FoqXSDAj4Rb8Nil8i4TMn1Ww.YSC8yz85uGLsYoz-eykNrP0GY3s8tK-zZ_F5iVINdbwMJWwuHTIj7nDXezbRptJ0vfKXGbD6PpkS3W0-QhmfMA&_sg%5B1%5D=VCNVRgpT0fEEjVPwTybRaS_yrZYEBVaeWFs000FY_mxtT8Qwj8iLsqxA5GonJ37tdDxIdBMU3Nl3iN6CetBu47l_8KCRT6pgbwp0juX7scYb.YSC8yz85uGLsYoz-eykNrP0GY3s8tK-zZ_F5iVINdbwMJWwuHTIj7nDXezbRptJ0vfKXGbD6PpkS3W0-QhmfMA&_iepl='>PDF</a>
              </div>
            </div>
          </div>
        </section>
      </main>
    </div>
  </div>
</body>

</html>
